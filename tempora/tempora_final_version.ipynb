{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747156a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T14:17:47.328331Z",
     "iopub.status.busy": "2025-06-12T14:17:47.328096Z",
     "iopub.status.idle": "2025-06-12T14:17:58.560176Z",
     "shell.execute_reply": "2025-06-12T14:17:58.559370Z"
    },
    "id": "J0JuvYEHYIdE",
    "outputId": "2f3da2f0-90fe-47dd-e70b-cc1921049b25",
    "papermill": {
     "duration": 11.237185,
     "end_time": "2025-06-12T14:17:58.561903",
     "exception": false,
     "start_time": "2025-06-12T14:17:47.324718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Device name : Tesla T4\n",
      "Tensor is on : cuda:0\n",
      "Number of weather stations: 422\n",
      "Number of days of data   : 695\n",
      "Number of weather variables (incl. cyclical): 78\n",
      "\n",
      "─ Normalisation summary ─\n",
      "Normalised array shape: (422, 695, 78)\n",
      "Train samples : 192,432\n",
      "Val   samples : 422\n",
      "Train loader: 1504 batches of 128\n",
      "Val   loader: 4 batches of 128\n"
     ]
    }
   ],
   "source": [
    "# ─── CELL 0  (ENV + DATA LOAD & PRE-PROCESSING with cyclical features and data augmentation) ───\n",
    "import torch, os, sys, platform, subprocess, textwrap, random\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name :\", torch.cuda.get_device_name(0))\n",
    "    dummy = torch.randn(256, 256).to(\"cuda\")\n",
    "    print(\"Tensor is on :\", dummy.device)\n",
    "\n",
    "# dont erase the follwoing commented line:\n",
    "data_dir = \"/kaggle/input/unipd-deep-learning-2025-challenge-2/\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Data & Loader parameters\n",
    "torch.set_num_threads(2)\n",
    "NUM_WORKERS = 4\n",
    "batch_size = 128\n",
    "input_len  = 90\n",
    "output_len = 30\n",
    "\n",
    "# Augmentation parameters\n",
    "noise_std      = 0.01             # jitter noise\n",
    "scaling_range  = (0.9, 1.1)         # magnitude scaling range\n",
    "dropout_prob   = 0.1              # feature/channel dropout probability\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Load raw dataset\n",
    "# ---------------------------------------------------------------------------\n",
    "data = pd.read_csv(data_dir + 'train_dataset.csv', index_col=[0, 1])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Add cyclical *day-of-year* features (sine & cosine)\n",
    "# ---------------------------------------------------------------------------\n",
    "idx_level_1 = data.index.get_level_values(1)\n",
    "\n",
    "if np.issubdtype(idx_level_1.dtype, np.integer):\n",
    "    day_number = idx_level_1.to_numpy()\n",
    "else:\n",
    "    parsed = pd.to_datetime(idx_level_1, errors=\"coerce\")\n",
    "    if parsed.notna().all():\n",
    "        day_number = parsed.dayofyear.to_numpy()\n",
    "    else:\n",
    "        day_number = np.arange(len(idx_level_1)) % 365\n",
    "\n",
    "period = 365.0\n",
    "\n",
    "data[\"doy_sin\"] = np.sin(2 * np.pi * day_number / period)\n",
    "data[\"doy_cos\"] = np.cos(2 * np.pi * day_number / period)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Convert to 3-D array  (station, day, feature)\n",
    "# ---------------------------------------------------------------------------\n",
    "stations = [station.values for _, station in data.groupby(level=0)]\n",
    "data_arr = np.stack(stations, axis=0)\n",
    "\n",
    "n_stations, n_days, n_features = data_arr.shape\n",
    "print(f\"Number of weather stations: {n_stations}\")\n",
    "print(f\"Number of days of data   : {n_days}\")\n",
    "print(f\"Number of weather variables (incl. cyclical): {n_features}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. Normalisation (mean / std computed on training period only)\n",
    "# ---------------------------------------------------------------------------\n",
    "feature_cols      = data.columns.tolist()  # var1 … var76 + doy_sin, doy_cos\n",
    "val_start_timestep = n_days - 30           # last 30 timesteps = validation target\n",
    "\n",
    "mask_train_period = data.index.get_level_values(1) < val_start_timestep\n",
    "train_means       = data.loc[mask_train_period, feature_cols].mean()\n",
    "train_stds        = data.loc[mask_train_period, feature_cols].std()\n",
    "\n",
    "data_norm = data.copy()\n",
    "data_norm[feature_cols] = (data_norm[feature_cols] - train_means) / train_stds\n",
    "\n",
    "stations_norm  = [station.values for _, station in data_norm.groupby(level=0)]\n",
    "data_arr_norm  = np.stack(stations_norm, axis=0)\n",
    "\n",
    "print(\"\\n─ Normalisation summary ─\")\n",
    "print(\"Normalised array shape:\", data_arr_norm.shape)   # (stations, days, features)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. Dataset & DataLoader with On-the-Fly Augmentation\n",
    "# ---------------------------------------------------------------------------\n",
    "val_input_start = n_days - (input_len + output_len)\n",
    "\n",
    "class WeatherWindowDataset(Dataset):\n",
    "    def __init__(self, data_3d: np.ndarray, mode=\"train\"):\n",
    "        self.data          = data_3d.astype(np.float32)\n",
    "        self.mode          = mode\n",
    "        self.in_len        = input_len\n",
    "        self.out_len       = output_len\n",
    "        self.jitter_std    = noise_std\n",
    "        self.scaling_low, self.scaling_high = scaling_range\n",
    "        self.dropout_prob  = dropout_prob\n",
    "\n",
    "        n_stations, n_days, _ = self.data.shape\n",
    "        if mode == \"train\":\n",
    "            last_start = val_input_start - self.in_len - self.out_len\n",
    "            idx = [(sid, t) for sid in range(n_stations) for t in range(0, last_start + 1)]\n",
    "        else:\n",
    "            idx = [(sid, val_input_start) for sid in range(n_stations)]\n",
    "        self.indices = np.asarray(idx, dtype=np.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid, start = self.indices[idx]\n",
    "        window = self.data[sid, start : start + self.in_len + self.out_len]\n",
    "        x = window[: self.in_len]    # (input_len, features)\n",
    "        y = window[self.in_len :]    # (output_len, features)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            # 1) Jitter noise\n",
    "            if self.jitter_std > 0:\n",
    "                x = x + self.jitter_std * np.random.randn(*x.shape).astype(np.float32)\n",
    "            # 2) Magnitude scaling\n",
    "            scales = np.random.uniform(self.scaling_low,\n",
    "                                       self.scaling_high,\n",
    "                                       size=(1, x.shape[1])).astype(np.float32)\n",
    "            x = x * scales\n",
    "            # 3) Channel dropout\n",
    "            mask = np.random.binomial(1, 1 - self.dropout_prob,\n",
    "                                      size=(1, x.shape[1])).astype(np.float32)\n",
    "            x = x * mask\n",
    "\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "# Instantiate datasets\n",
    "train_ds = WeatherWindowDataset(data_arr_norm, mode=\"train\")\n",
    "val_ds   = WeatherWindowDataset(data_arr_norm, mode=\"val\")\n",
    "\n",
    "print(f\"Train samples : {len(train_ds):,}\")\n",
    "print(f\"Val   samples : {len(val_ds):,}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size,\n",
    "                          shuffle=True,  pin_memory=True, num_workers=NUM_WORKERS)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size,\n",
    "                          shuffle=False, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches of {batch_size}\")\n",
    "print(f\"Val   loader: {len(val_loader)} batches of {batch_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46211b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T14:17:58.570229Z",
     "iopub.status.busy": "2025-06-12T14:17:58.570007Z",
     "iopub.status.idle": "2025-06-12T16:37:53.638371Z",
     "shell.execute_reply": "2025-06-12T16:37:53.637402Z"
    },
    "id": "L398SHx-kpbI",
    "outputId": "9bbdbf13-230c-4af6-fa56-73c9aad2b6e4",
    "papermill": {
     "duration": 8395.078255,
     "end_time": "2025-06-12T16:37:53.644271",
     "exception": false,
     "start_time": "2025-06-12T14:17:58.566016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "=== TRAINING GRUSeq2Seq (new1, seed=23) ===\n",
      "Epoch 1/50 | LR 1.4e-05 | TF 1.00 | Train MSE 0.7661 | Val MAE 1658.96\n",
      "Epoch 2/50 | LR 1.9e-05 | TF 0.89 | Train MSE 0.5566 | Val MAE 1559.68\n",
      "Epoch 3/50 | LR 2.8e-05 | TF 0.78 | Train MSE 0.4959 | Val MAE 1495.30\n",
      "Epoch 4/50 | LR 4.0e-05 | TF 0.67 | Train MSE 0.4941 | Val MAE 1441.91\n",
      "Epoch 5/50 | LR 5.4e-05 | TF 0.56 | Train MSE 0.5147 | Val MAE 1352.63\n",
      "Epoch 6/50 | LR 7.1e-05 | TF 0.44 | Train MSE 0.5421 | Val MAE 1429.25\n",
      "Epoch 7/50 | LR 9.1e-05 | TF 0.33 | Train MSE 0.5817 | Val MAE 1425.59\n",
      "Epoch 8/50 | LR 1.1e-04 | TF 0.22 | Train MSE 0.6354 | Val MAE 1459.25\n",
      "Epoch 9/50 | LR 1.3e-04 | TF 0.11 | Train MSE 0.7037 | Val MAE 1458.87\n",
      "Epoch 10/50 | LR 1.6e-04 | TF 0.00 | Train MSE 0.7805 | Val MAE 1462.21\n",
      "Epoch 11/50 | LR 1.8e-04 | TF 0.00 | Train MSE 0.7532 | Val MAE 1461.95\n",
      "Epoch 12/50 | LR 2.0e-04 | TF 0.00 | Train MSE 0.7205 | Val MAE 1414.78\n",
      "Epoch 13/50 | LR 2.2e-04 | TF 0.00 | Train MSE 0.6851 | Val MAE 1444.96\n",
      "Epoch 14/50 | LR 2.4e-04 | TF 0.00 | Train MSE 0.6513 | Val MAE 1455.40\n",
      "Epoch 15/50 | LR 2.6e-04 | TF 0.00 | Train MSE 0.6169 | Val MAE 1478.62\n",
      "Early stopping.\n",
      "=== TRAINING GRUSeq2Seq (new2, seed=105) ===\n",
      "Epoch 1/50 | LR 1.4e-05 | TF 1.00 | Train MSE 0.7628 | Val MAE 1665.64\n",
      "Epoch 2/50 | LR 1.9e-05 | TF 0.89 | Train MSE 0.5567 | Val MAE 1556.39\n",
      "Epoch 3/50 | LR 2.8e-05 | TF 0.78 | Train MSE 0.4958 | Val MAE 1493.12\n",
      "Epoch 4/50 | LR 4.0e-05 | TF 0.67 | Train MSE 0.4950 | Val MAE 1415.55\n",
      "Epoch 5/50 | LR 5.4e-05 | TF 0.56 | Train MSE 0.5105 | Val MAE 1364.96\n",
      "Epoch 6/50 | LR 7.1e-05 | TF 0.44 | Train MSE 0.5390 | Val MAE 1392.95\n",
      "Epoch 7/50 | LR 9.1e-05 | TF 0.33 | Train MSE 0.5814 | Val MAE 1438.23\n",
      "Epoch 8/50 | LR 1.1e-04 | TF 0.22 | Train MSE 0.6347 | Val MAE 1466.36\n",
      "Epoch 9/50 | LR 1.3e-04 | TF 0.11 | Train MSE 0.7005 | Val MAE 1462.69\n",
      "Epoch 10/50 | LR 1.6e-04 | TF 0.00 | Train MSE 0.7811 | Val MAE 1479.33\n",
      "Epoch 11/50 | LR 1.8e-04 | TF 0.00 | Train MSE 0.7514 | Val MAE 1475.88\n",
      "Epoch 12/50 | LR 2.0e-04 | TF 0.00 | Train MSE 0.7183 | Val MAE 1463.34\n",
      "Epoch 13/50 | LR 2.2e-04 | TF 0.00 | Train MSE 0.6768 | Val MAE 1475.26\n",
      "Epoch 14/50 | LR 2.4e-04 | TF 0.00 | Train MSE 0.6361 | Val MAE 1470.53\n",
      "Epoch 15/50 | LR 2.6e-04 | TF 0.00 | Train MSE 0.5997 | Val MAE 1465.90\n",
      "Early stopping.\n",
      "=== TRAINING GRUSeq2Seq (new3, seed=100) ===\n",
      "Epoch 1/50 | LR 1.4e-05 | TF 1.00 | Train MSE 0.7645 | Val MAE 1653.43\n",
      "Epoch 2/50 | LR 1.9e-05 | TF 0.89 | Train MSE 0.5545 | Val MAE 1557.83\n",
      "Epoch 3/50 | LR 2.8e-05 | TF 0.78 | Train MSE 0.4954 | Val MAE 1489.94\n",
      "Epoch 4/50 | LR 4.0e-05 | TF 0.67 | Train MSE 0.4957 | Val MAE 1369.92\n",
      "Epoch 5/50 | LR 5.4e-05 | TF 0.56 | Train MSE 0.5113 | Val MAE 1385.46\n",
      "Epoch 6/50 | LR 7.1e-05 | TF 0.44 | Train MSE 0.5401 | Val MAE 1409.33\n",
      "Epoch 7/50 | LR 9.1e-05 | TF 0.33 | Train MSE 0.5798 | Val MAE 1415.91\n",
      "Epoch 8/50 | LR 1.1e-04 | TF 0.22 | Train MSE 0.6314 | Val MAE 1450.59\n",
      "Epoch 9/50 | LR 1.3e-04 | TF 0.11 | Train MSE 0.7016 | Val MAE 1477.51\n",
      "Epoch 10/50 | LR 1.6e-04 | TF 0.00 | Train MSE 0.7796 | Val MAE 1472.35\n",
      "Epoch 11/50 | LR 1.8e-04 | TF 0.00 | Train MSE 0.7534 | Val MAE 1463.73\n",
      "Epoch 12/50 | LR 2.0e-04 | TF 0.00 | Train MSE 0.7226 | Val MAE 1442.20\n",
      "Epoch 13/50 | LR 2.2e-04 | TF 0.00 | Train MSE 0.6879 | Val MAE 1449.23\n",
      "Epoch 14/50 | LR 2.4e-04 | TF 0.00 | Train MSE 0.6509 | Val MAE 1474.75\n",
      "Early stopping.\n",
      "=== TRAINING GRUSeq2Seq (orig, seed=104) ===\n",
      "Epoch 1/50 | LR 1.4e-05 | TF 1.00 | Train MSE 0.7664 | Val MAE 1659.02\n",
      "Epoch 2/50 | LR 1.9e-05 | TF 0.89 | Train MSE 0.5569 | Val MAE 1566.85\n",
      "Epoch 3/50 | LR 2.8e-05 | TF 0.78 | Train MSE 0.4979 | Val MAE 1478.75\n",
      "Epoch 4/50 | LR 4.0e-05 | TF 0.67 | Train MSE 0.4965 | Val MAE 1371.94\n",
      "Epoch 5/50 | LR 5.4e-05 | TF 0.56 | Train MSE 0.5111 | Val MAE 1404.65\n",
      "Epoch 6/50 | LR 7.1e-05 | TF 0.44 | Train MSE 0.5394 | Val MAE 1417.29\n",
      "Epoch 7/50 | LR 9.1e-05 | TF 0.33 | Train MSE 0.5818 | Val MAE 1421.65\n",
      "Epoch 8/50 | LR 1.1e-04 | TF 0.22 | Train MSE 0.6382 | Val MAE 1425.27\n",
      "Epoch 9/50 | LR 1.3e-04 | TF 0.11 | Train MSE 0.7046 | Val MAE 1460.03\n",
      "Epoch 10/50 | LR 1.6e-04 | TF 0.00 | Train MSE 0.7825 | Val MAE 1421.65\n",
      "Epoch 11/50 | LR 1.8e-04 | TF 0.00 | Train MSE 0.7552 | Val MAE 1412.42\n",
      "Epoch 12/50 | LR 2.0e-04 | TF 0.00 | Train MSE 0.7242 | Val MAE 1452.73\n",
      "Epoch 13/50 | LR 2.2e-04 | TF 0.00 | Train MSE 0.6817 | Val MAE 1486.29\n",
      "Epoch 14/50 | LR 2.4e-04 | TF 0.00 | Train MSE 0.6385 | Val MAE 1446.30\n",
      "Early stopping.\n",
      "=== TRAINING GRUSeq2Seq (rep, seed=22) ===\n",
      "Epoch 1/50 | LR 1.4e-05 | TF 1.00 | Train MSE 0.7677 | Val MAE 1661.61\n",
      "Epoch 2/50 | LR 1.9e-05 | TF 0.89 | Train MSE 0.5561 | Val MAE 1564.54\n",
      "Epoch 3/50 | LR 2.8e-05 | TF 0.78 | Train MSE 0.4953 | Val MAE 1467.95\n",
      "Epoch 4/50 | LR 4.0e-05 | TF 0.67 | Train MSE 0.4930 | Val MAE 1376.63\n",
      "Epoch 5/50 | LR 5.4e-05 | TF 0.56 | Train MSE 0.5108 | Val MAE 1376.58\n",
      "Epoch 6/50 | LR 7.1e-05 | TF 0.44 | Train MSE 0.5373 | Val MAE 1413.80\n",
      "Epoch 7/50 | LR 9.1e-05 | TF 0.33 | Train MSE 0.5793 | Val MAE 1436.77\n",
      "Epoch 8/50 | LR 1.1e-04 | TF 0.22 | Train MSE 0.6316 | Val MAE 1445.25\n",
      "Epoch 9/50 | LR 1.3e-04 | TF 0.11 | Train MSE 0.6984 | Val MAE 1474.77\n",
      "Epoch 10/50 | LR 1.6e-04 | TF 0.00 | Train MSE 0.7779 | Val MAE 1458.56\n",
      "Epoch 11/50 | LR 1.8e-04 | TF 0.00 | Train MSE 0.7471 | Val MAE 1474.72\n",
      "Epoch 12/50 | LR 2.0e-04 | TF 0.00 | Train MSE 0.7152 | Val MAE 1460.41\n",
      "Epoch 13/50 | LR 2.2e-04 | TF 0.00 | Train MSE 0.6782 | Val MAE 1468.06\n",
      "Epoch 14/50 | LR 2.4e-04 | TF 0.00 | Train MSE 0.6405 | Val MAE 1468.30\n",
      "Epoch 15/50 | LR 2.6e-04 | TF 0.00 | Train MSE 0.6059 | Val MAE 1458.77\n",
      "Early stopping.\n",
      "Best Val MAE → GRU(new1): 1352.63, GRU(new2): 1364.96, GRU(new3): 1369.92, GRU(orig): 1371.94, GRU(rep): 1376.58\n"
     ]
    }
   ],
   "source": [
    "import math, random, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# --------------------- Device Setup ---------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --------------------- Hyperparameters ---------------------\n",
    "SEED_GRU_NEW1 = 23   # first substituted GRU seed\n",
    "SEED_GRU_NEW2 = 105  # second substituted GRU seed\n",
    "SEED_GRU_NEW3 = 100  # third substituted GRU seed\n",
    "SEED_GRU1    = 104  # original GRU seed\n",
    "SEED_GRU2    = 22   # second GRU seed\n",
    "NUM_EPOCHS   = 50\n",
    "PATIENCE     = 10\n",
    "BASE_LR      = 3e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "CLIP_NORM    = 1.0\n",
    "TF_EPOCHS    = 10\n",
    "\n",
    "# GRU hyperparams (used for all GRUs)\n",
    "gru_hidden, gru_layers, gru_dropout = 256, 2, 0.01\n",
    "\n",
    "input_size = n_features\n",
    "input_len  = input_len\n",
    "output_len = output_len\n",
    "\n",
    "# ------------------ Model Definitions ------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class TransformerForecast(nn.Module):\n",
    "    def __init__(self, input_size, d_model, nhead, num_layers, dim_feedforward, dropout, out_len, max_len):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_size, d_model)\n",
    "        self.pos_enc    = PositionalEncoding(d_model, max_len)\n",
    "        layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.encoder    = nn.TransformerEncoder(layer, num_layers)\n",
    "        self.fc_out     = nn.Linear(d_model, input_size * out_len)\n",
    "        self.out_len    = out_len\n",
    "\n",
    "    def forward(self, x, y=None, tf_ratio=None):\n",
    "        x = self.pos_enc(self.input_proj(x))\n",
    "        enc = self.encoder(x)\n",
    "        h   = enc[:, -1, :]\n",
    "        return self.fc_out(h).view(x.size(0), self.out_len, -1)\n",
    "\n",
    "class GRUSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, out_len):\n",
    "        super().__init__()\n",
    "        self.out_len = out_len\n",
    "        self.encoder = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out  = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x, y=None, tf_ratio=1.0):\n",
    "        _, h = self.encoder(x)\n",
    "        dec_in = x[:, -1:, :]\n",
    "        outs = []\n",
    "        for t in range(self.out_len):\n",
    "            out, h = self.decoder(dec_in, h)\n",
    "            pred = self.fc_out(out.squeeze(1))\n",
    "            outs.append(pred.unsqueeze(1))\n",
    "            take_gt = (y is not None) and (torch.rand(1).item() < tf_ratio)\n",
    "            dec_in  = y[:, t:t+1, :] if take_gt else pred.unsqueeze(1)\n",
    "        return torch.cat(outs, 1)\n",
    "\n",
    "# ---------------- Helper: Teacher-forcing schedule ----------------\n",
    "def tf_ratio(epoch: int) -> float:\n",
    "    return max(0.0, 1.0 - (epoch - 1)/(TF_EPOCHS - 1))\n",
    "\n",
    "# ---------------- Training Helper ----------------\n",
    "def train_model(model, train_loader, val_loader, num_epochs):\n",
    "    model = model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=BASE_LR, epochs=num_epochs,\n",
    "                           steps_per_epoch=len(train_loader), pct_start=0.4)\n",
    "    best_val, best_state, no_imp = float('inf'), None, 0\n",
    "    mae_loss = nn.L1Loss()\n",
    "    for ep in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        mse_acc = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                preds = model(xb, yb, tf_ratio(ep))\n",
    "                loss  = mae_loss(preds, yb)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            mse_acc += torch.mean((preds - yb) ** 2).item() * xb.size(0)\n",
    "        train_mse = mse_acc / len(train_loader.dataset)\n",
    "        model.eval()\n",
    "        mae_sum = 0.0\n",
    "        with torch.no_grad(), autocast(device_type=\"cuda\"):\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                yhat = model(xb, None, tf_ratio(1))\n",
    "                mae_sum += torch.abs(yhat - yb).sum().item()\n",
    "        val_mae = mae_sum / len(val_loader.dataset)\n",
    "        print(f\"Epoch {ep}/{num_epochs} | LR {scheduler.get_last_lr()[0]:.1e} | TF {tf_ratio(ep):.2f}\"  \\\n",
    "              f\" | Train MSE {train_mse:.4f} | Val MAE {val_mae:.2f}\")\n",
    "        if val_mae < best_val:\n",
    "            best_val, best_state, no_imp = val_mae, copy.deepcopy(model.state_dict()), 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "            if no_imp >= PATIENCE:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "    model.load_state_dict(best_state)\n",
    "    return model, best_val\n",
    "\n",
    "# ─── Train GRUSeq2Seq (new1, seed=23) ───\n",
    "random.seed(SEED_GRU_NEW1)\n",
    "np.random.seed(SEED_GRU_NEW1)\n",
    "torch.manual_seed(SEED_GRU_NEW1)\n",
    "torch.cuda.manual_seed_all(SEED_GRU_NEW1)\n",
    "print(f\"=== TRAINING GRUSeq2Seq (new1, seed={SEED_GRU_NEW1}) ===\")\n",
    "model_gru3, best_val_gru3 = train_model(GRUSeq2Seq(input_size, gru_hidden, gru_layers, gru_dropout, output_len), train_loader, val_loader, NUM_EPOCHS)\n",
    "\n",
    "# ─── Train GRUSeq2Seq (new2, seed=105) ───\n",
    "random.seed(SEED_GRU_NEW2)\n",
    "np.random.seed(SEED_GRU_NEW2)\n",
    "torch.manual_seed(SEED_GRU_NEW2)\n",
    "torch.cuda.manual_seed_all(SEED_GRU_NEW2)\n",
    "print(f\"=== TRAINING GRUSeq2Seq (new2, seed={SEED_GRU_NEW2}) ===\")\n",
    "model_gru4, best_val_gru4 = train_model(GRUSeq2Seq(input_size, gru_hidden, gru_layers, gru_dropout, output_len), train_loader, val_loader, NUM_EPOCHS)\n",
    "\n",
    "# ─── Train GRUSeq2Seq (new3, seed=100) ───\n",
    "random.seed(SEED_GRU_NEW3)\n",
    "np.random.seed(SEED_GRU_NEW3)\n",
    "torch.manual_seed(SEED_GRU_NEW3)\n",
    "torch.cuda.manual_seed_all(SEED_GRU_NEW3)\n",
    "print(f\"=== TRAINING GRUSeq2Seq (new3, seed={SEED_GRU_NEW3}) ===\")\n",
    "model_gru5, best_val_gru5 = train_model(GRUSeq2Seq(input_size, gru_hidden, gru_layers, gru_dropout, output_len), train_loader, val_loader, NUM_EPOCHS)\n",
    "\n",
    "# ─── Train GRUSeq2Seq (orig, seed=104) ───\n",
    "random.seed(SEED_GRU1)\n",
    "np.random.seed(SEED_GRU1)\n",
    "torch.manual_seed(SEED_GRU1)\n",
    "torch.cuda.manual_seed_all(SEED_GRU1)\n",
    "print(f\"=== TRAINING GRUSeq2Seq (orig, seed={SEED_GRU1}) ===\")\n",
    "model_gru1, best_val_gru1 = train_model(GRUSeq2Seq(input_size, gru_hidden, gru_layers, gru_dropout, output_len),train_loader, val_loader, NUM_EPOCHS)\n",
    "\n",
    "# ─── Train GRUSeq2Seq (rep, seed=22) ───\n",
    "random.seed(SEED_GRU2)\n",
    "np.random.seed(SEED_GRU2)\n",
    "torch.manual_seed(SEED_GRU2)\n",
    "torch.cuda.manual_seed_all(SEED_GRU2)\n",
    "print(f\"=== TRAINING GRUSeq2Seq (rep, seed={SEED_GRU2}) ===\")\n",
    "model_gru2, best_val_gru2 = train_model(GRUSeq2Seq(input_size, gru_hidden, gru_layers, gru_dropout, output_len),train_loader, val_loader, NUM_EPOCHS)\n",
    "\n",
    "# Final summary\n",
    "print(\n",
    "    f\"Best Val MAE → GRU(new1): {best_val_gru3:.2f}, GRU(new2): {best_val_gru4:.2f}, GRU(new3): {best_val_gru5:.2f}, \"\n",
    "    f\"GRU(orig): {best_val_gru1:.2f}, GRU(rep): {best_val_gru2:.2f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7c860d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T16:37:53.655022Z",
     "iopub.status.busy": "2025-06-12T16:37:53.654472Z",
     "iopub.status.idle": "2025-06-12T16:37:55.572048Z",
     "shell.execute_reply": "2025-06-12T16:37:55.571357Z"
    },
    "id": "vjg2lIM7HwIE",
    "outputId": "2cc23b8a-b223-45ad-b278-0f0f9a585001",
    "papermill": {
     "duration": 1.924422,
     "end_time": "2025-06-12T16:37:55.573250",
     "exception": false,
     "start_time": "2025-06-12T16:37:53.648828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission.csv with shape (12660, 77)\n"
     ]
    }
   ],
   "source": [
    "# ─── CELL 2: Inference & Submission (Updated Models) ───\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensemble inference over five models\n",
    "models = [model_gru3, model_gru4, model_gru5, model_gru1, model_gru2]\n",
    "for m in models:\n",
    "    m.eval()\n",
    "\n",
    "# 1) Prepare input window\n",
    "input_window = data_arr_norm[:, -input_len:, :].astype(np.float32)  # (stations, input_len, features)\n",
    "x_in = torch.from_numpy(input_window).to(device)\n",
    "\n",
    "# 2) Generate predictions\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    preds.append(model_gru3(x_in, None, tf_ratio(0)))\n",
    "    preds.append(model_gru4(x_in, None, tf_ratio(0)))\n",
    "    preds.append(model_gru5(x_in, None, tf_ratio(0)))\n",
    "    preds.append(model_gru1(x_in, None, tf_ratio(0)))\n",
    "    preds.append(model_gru2(x_in, None, tf_ratio(0)))\n",
    "# move to numpy\n",
    "preds = [p.cpu().numpy() for p in preds]\n",
    "\n",
    "# 3) Compute ensemble weights from validation MAEs\n",
    "val_scores = np.array([best_val_gru3, best_val_gru4, best_val_gru5, best_val_gru1, best_val_gru2])\n",
    "weights = 1.0 / val_scores\n",
    "weights /= weights.sum()\n",
    "\n",
    "# 4) Weighted ensemble\n",
    "ensemble_norm = np.tensordot(weights, np.stack(preds, axis=0), axes=(0,0))  # (stations, out_len, features)\n",
    "\n",
    "# 5) Denormalize\n",
    "means = train_means.values.reshape(1,1,-1)\n",
    "stds  = train_stds.values.reshape(1,1,-1)\n",
    "ensemble_raw = ensemble_norm * stds + means\n",
    "\n",
    "# 6) Discard cyclical features (last two)\n",
    "ensemble_vars = ensemble_raw[:, :, :-2]  # shape (stations, out_len, var_count)\n",
    "\n",
    "# 7) Build submission DataFrame\n",
    "n_stations, H, n_vars = ensemble_vars.shape\n",
    "# sanity check: ensure only 76 variables are output\n",
    "assert n_vars == 76, f\"Expected 76 variables, got {n_vars}\"\n",
    "rows = []\n",
    "for sid in range(n_stations):\n",
    "    for t in range(H):\n",
    "        idx = f\"{sid}_{t}\"\n",
    "        rows.append([idx] + ensemble_vars[sid, t].tolist())\n",
    "var_cols = [f\"var{i+1}\" for i in range(n_vars)]\n",
    "sub_df = pd.DataFrame(rows, columns=[\"id\"] + var_cols)\n",
    "\n",
    "# 8) Save\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv with shape\", sub_df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12429606,
     "sourceId": 102815,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8415.698127,
   "end_time": "2025-06-12T16:37:58.762918",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T14:17:43.064791",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
